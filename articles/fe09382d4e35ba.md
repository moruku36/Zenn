---
title: "Azure Open AIのコーポレートガバナンスについて考える"
emoji: "🦔"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [Azure, ChatGPT, OpenAI,　AzureOpenAI, Governance]
published: true
---
## はじめに
業務でAzure Open AI のガバナンスについてどう考える？というふわっとした質問を受けたので、AIと一緒に調べてみました。

本記事では、Azure OpenAIのコーポレートガバナンスについて、以下の観点から考えてみたいと思います。

- Azure OpenAIが処理するデータの種類と目的
- Azure OpenAIがデータをどのように処理するか
- Azure OpenAIがデータをどのように保持し、顧客がどのようにコントロールできるか
- Azure OpenAIがどのように責任あるAIの原則を実践するか

## Azure OpenAIが処理するデータの種類と目的
Azure OpenAIは、以下の種類のデータを処理します。

- テキストプロンプト、クエリー、レスポンス: これらは、completions, search, embeddingsという操作を通じてユーザーが提出するテキストです。これらのデータは、サービスを提供し、悪用や有害なコンテンツ生成を監視し、Azure OpenAIの責任あるAIシステムの品質を開発・改善するために使用されます。
- トレーニング・バリデーションデータ: これらは、OpenAIモデルをファインチューニングするためにユーザーが提供するプロンプト・コンプリーションペアです。これらのデータは、ユーザー自身のモデルをファインチューニングするためにのみ使用され、Microsoftが他のモデルをトレーニングや改善するために使用することはありません。
- トレーニングプロセスから得られる結果データ: ファインチューニングされたモデルをトレーニングした後、サービスはジョブに関するメタデータを出力します。これには、各ステップで処理されたトークン数やバリデーションスコアなどが含まれます。

https://learn.microsoft.com/ja-jp/legal/cognitive-services/openai/data-privacy

## Azure OpenAIがデータをどのように処理するか
以下の図は、データがどのように処理されるかを示しています。この図は、次の3つの異なるタイプの処理をカバーしています。

![Azure OpenAI data processing diagram](https://docs.microsoft.com/en-us/learn/azure/cognitive-services/openai/media/data-privacy.png)

- トレーニングデータを使ってOpenAIモデルをファインチューニングする方法
- テキストプロンプトを処理してコンプリーション、埋め込み、検索結果を生成する
- Azure OpenAIとMicrosoftの人員がプロンプトとコンプリーションを分析して、悪用や誤用、有害なコンテンツ生成を検出する方法

トレーニングデータのファインチューニングに関しては、以下の点に注意してください。

- ファインチューニングAPIを通じてAzure OpenAI Studioに送信されたトレーニングデータ（プロンプト・コンプリーションペア）は、自動ツールを使って品質チェックされます。これには、データ形式のチェックなどが含まれます。
- トレーニングデータは、Azure OpenAIプラットフォーム上のモデルトレーニングコンポーネントにインポートされます。トレーニングプロセス中、トレーニングデータはバッチに分解され、OpenAIモデルの重みを修正するために使用されます。
- 顧客が提供したトレーニングデータは、顧客自身のモデルをファインチューニングするためにのみ使用され、Microsoftが他のモデルをトレーニングや改善するために使用することはありません。

テキストプロンプトの処理に関しては、以下の点に注意してください。

- モデルがデプロイされると、REST API、クライアントライブラリ、またはAzure OpenAI Studioを使って、Completions操作でテキストを生成できます。
- Completions操作では、テキストプロンプトとともにいくつかのパラメーターを指定できます。これらのパラメーターは、生成されるテキストの長さや品質などを制御します。
- Completions操作では、テキストプロンプトをトークン化し、OpenAIモデルに入力します。OpenAIモデルは、テキストプロンプトに続く最も可能性の高いテキストを生成します。生成されたテキストは、顧客に返される前にフィルタリングシステムによってスキャンされます。フィルタリングシステムは、有害なコンテンツや個人情報などを検出し、必要に応じてブロックや警告を行います。

悪用や有害なコンテンツ生成の監視と分析に関しては、以下の点に注意してください。

- 悪用や有害なコンテンツ生成を監視するために、サービスから送信されたプロンプトとコンプリーションを保存します。これらのデータは、Azure OpenAIの責任あるAIシステムの品質を開発・改善するためにも使用されます。
- Microsoftは、悪用や有害なコンテンツ生成を検出し、対策を講じます。サービスから送信されたプロンプトとコンプリーションの一部をランダムにサンプリングし、定期的にレビューします。Microsoftはまた、顧客から報告された問題や懸念事項を報告する方法や、サービスの使用に関するガイドラインを確認します。悪用や有害なコンテンツ生成のパターンや傾向を分析し、フィルタリングシステムやモデルの改善にフィードバックします。

## Azure OpenAIがデータをどのように保持し、顧客がどのようにコントロールできるか
Azure OpenAIは、以下のようにデータを保持します。

- テキストプロンプト、クエリー、レスポンス: これらのデータは、サービスを提供し、悪用や有害なコンテンツ生成を監視し、Azure OpenAIの責任あるAIシステムの品質を開発・改善するために最大90日間保存されます。顧客は、Azureポータルからこれらのデータを削除することができます。
- トレーニング・バリデーションデータ: これらのデータは、ファインチューニングされたモデルが削除されるまで保存されます。顧客は、Azureポータルからこれらのデータとモデルを削除することができます。
- トレーニングプロセスから得られる結果データ: これらのデータは、ファインチューニングされたモデルが削除されるまで保存されます。顧客は、Azureポータルからこれらのデータとモデルを削除することができます。

Azure OpenAIは、以下のように顧客がデータをコントロールできるようにします。

- Azureポータルから自分のアカウントに関連付けられたすべてのデータを確認し、必要に応じて削除することができます。
- Azureポータルから自分のアカウントに関連付けられたすべてのモデルを確認し、必要に応じて削除することができます。
- Microsoft Products and Services Data Protection Addendumに従って、自分のアカウントに関連付けられたすべてのデータをエクスポートすることができます。

## Azure OpenAIがどのように責任あるAIの原則を実践するか
Azure OpenAIは、Microsoftが掲げる責任あるAIの原則に沿って開発されています。これらの原則は以下の通りです。


- 説明責任: AIシステムは人間が責任を持って設計・運用されるべきであり、その影響や結果に対して説明責任を果たすべきである。
- 包摂性: AIシステムは多様なニーズや視点を反映し、不公平なバイアスや差別を排除するべきである。
- 信頼性と安全性: AIシステムは正確で安全で信頼できるものであり、予期しない結果や悪意ある利用に対して耐性があるべきである。
- 公平性: AIシステムは、すべての人に公平に利益をもたらし、不利益を与えないようにするべきである。
- 透明性: AIシステムは、その機能や制限、意思決定の根拠などを明確に伝えるべきである。
- プライバシーとセキュリティ: AIシステムは、個人のプライバシーとセキュリティを尊重し、保護するべきである。  

https://www.microsoft.com/ja-jp/ai/responsible-ai?activetab=pivot1%3aprimaryr6

Azure OpenAIは、これらの原則を実践するために、以下のような取り組みを行っています。

- 説明責任: Microsoftの責任あるAI委員会やエンジニアリングチームなどの内部的なガバナンス機構によって監督されています。また、顧客や社会との対話やフィードバックを通じて、外部的な説明責任も果たしています。
- 包摂性: 多様なデータや言語をサポートし、ユーザーが自分のニーズや目的に合わせてモデルをファインチューニングできるようにしています。また、不公平なバイアスや差別を検出し、軽減するためのツールやガイドラインを提供しています。
- 信頼性と安全性: 、高い品質とパフォーマンスを維持するために、定期的にモデルのテストや評価を行っています。また、予期しない結果や悪意ある利用を防ぐために、フィルタリングシステムや警告メッセージなどの仕組みを備えています。
- 公平性: モデルが生成するテキストが公平であることを確認するために、バイアスや差別的な言葉や表現を検出し、排除するためのシステムを開発しています。また、ユーザーが自分のモデルの公平性を評価し、改善するためのツールやガイドラインを提供しています。
- 透明性: 、モデルの機能や制限、意思決定の根拠などを明確に伝えるために、ドキュメンテーションやチュートリアルなどのリソースを提供しています。また、ユーザーが自分のデータやモデルに関する情報を確認し、管理できるようにしています。
- プライバシーとセキュリティ:個人のプライバシーとセキュリティを尊重し、保護するために、Microsoft Products and Services Data Protection AddendumやAzure Cognitive Services Termsなどの法的な契約に従っています。また、ユーザーが自分のデータを削除したりエクスポートしたりできるようにしています。

## まとめ
本記事では、Azure OpenAIのコーポレートガバナンスについて、4つの観点から紹介しました。
ガバナンスやコンプライアンスの観点では、Azure Open AIサービスはMicrosoftのコンプライアンスフレームワークに準拠しているようです。

今後はセキュリティやネットワークなどインフラ観点についても技術検証含めて調べてみたいと思います。